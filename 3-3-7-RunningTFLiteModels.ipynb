{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_2_7_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1J15Vh_1Jih",
        "cellView": "both"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqNRQoc7W17k",
        "outputId": "0f4ffed8-df61-4403-e38c-3dee451dec36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np # import numpy\n",
        "import matplotlib.pylab as plt # matplotlib as plt\n",
        "\n",
        "import tensorflow as tf # import tensorflow\n",
        "import tensorflow_hub as hub # examples\n",
        "import tensorflow_datasets as tfds # datasets\n",
        "\n",
        "\n",
        "def format_image(image, label): \n",
        "    image = tf.image.resize(image, (224, 224)) / 255.0 # reformat image to fit 224,224 and normalise it by dividing by 255.0\n",
        "    return  image, label\n",
        "\n",
        "\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load( # meta data ontains additional info about the dataset such as version, citation, homepage,description...\n",
        "    'cats_vs_dogs', # load cats vs dogs from dataset into a tf.data.Dataset\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'], #raw_train= 80% , raw_validation=80%-90% validation, raw_test= 90%-100%\n",
        "    with_info=True, #\n",
        "    as_supervised=True, #returned dataset has (input,label) structure, else a dictionary is returned.\n",
        ")\n",
        "#metadata=tfds.core.DatasetInfo\n",
        "num_examples = metadata.splits['train'].num_examples #  splits='train': 23262,},\n",
        "num_classes = metadata.features['label'].num_classes #features=FeaturesDict({ 'image': Image(shape=(None, None, 3), dtype=tf.uint8), 'image/filename': Text(shape=(), dtype=tf.string), 'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),}),\n",
        "print(num_examples)\n",
        "print(num_classes)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_batches = raw_train.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)# shuffled training (image,label) is formatted using map(format_image) and batched into a batch of 32 images . \n",
        "validation_batches = raw_validation.map(format_image).batch(BATCH_SIZE).prefetch(1) # validation set is formatted using map(format_image) and batched into a batch of 32 images.\n",
        "test_batches = raw_test.map(format_image).batch(1)\n",
        "\n",
        "for image_batch, label_batch in train_batches.take(1):\n",
        "    pass\n",
        "\n",
        "image_batch.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23262\n",
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 224, 224, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90nEkGabHhrM",
        "outputId": "962883c3-384b-47ac-965b-e74496b650c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "23262//4"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5815"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inIK227eZbgV"
      },
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280) # mobilenet nn\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))\n",
        "\n",
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE + (3,), \n",
        "                                   output_shape=[FV_SIZE],\n",
        "                                   trainable=False)\n",
        "\n",
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        feature_extractor,\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "hist = model.fit(train_batches,\n",
        "                 epochs=EPOCHS,\n",
        "                 validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cML-V4yqtuYI"
      },
      "source": [
        "CATS_VS_DOGS_SAVED_MODEL = \"exp_saved_model\"\n",
        "tf.saved_model.save(model, CATS_VS_DOGS_SAVED_MODEL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gButZXqZt3o4"
      },
      "source": [
        "import pathlib\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "tflite_models_dir = pathlib.Path(\"/tmp/\")\n",
        "\n",
        "tflite_model_file = tflite_models_dir/'model1.tflite'\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "# This will report back the file size in bytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsNjuPhxuDOx"
      },
      "source": [
        "from tqdm import tqdm\n",
        "# Load TFLite model and allocate tensors.\n",
        "tflite_model_file = '/tmp/model1.tflite'\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "predictions = []\n",
        "\n",
        "# This will report how many iterations per second, where each\n",
        "# iteration is 100 predictions\n",
        "test_labels, test_imgs = [], []\n",
        "for img, label in tqdm(test_batches.take(100)):\n",
        "    interpreter.set_tensor(input_index, img)\n",
        "    interpreter.invoke()\n",
        "    predictions.append(interpreter.get_tensor(output_index))\n",
        "    \n",
        "    test_labels.append(label.numpy()[0])\n",
        "    test_imgs.append(img)\n",
        "\n",
        "\n",
        "# This will tell you how many of the predictions were correct\n",
        "score = 0\n",
        "for item in range(0,len(predictions)):\n",
        "  prediction=np.argmax(predictions[item])\n",
        "  label = test_labels[item]\n",
        "  if prediction==label:\n",
        "    score=score+1\n",
        "\n",
        "print(\"Out of 100 predictions I got \" + str(score) + \" correct\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRgWsPmDuJEI"
      },
      "source": [
        "\n",
        "#@title Utility functions for plotting\n",
        "# Utilities for plotting\n",
        "\n",
        "class_names = ['cat', 'dog']\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    img = np.squeeze(img)\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "    \n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    \n",
        "    if predicted_label == true_label:\n",
        "        color = 'green'\n",
        "    else:\n",
        "        color = 'red'\n",
        "    \n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                         100*np.max(predictions_array),\n",
        "                                         class_names[true_label]), color=color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TylXFi0quLEw"
      },
      "source": [
        "\n",
        "#@title Visualize the outputs { run: \"auto\" }\n",
        "max_index = 73 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "for index in range(0,max_index):\n",
        "  plt.figure(figsize=(6,3))\n",
        "  plt.subplot(1,2,1)\n",
        "  plot_image(index, predictions, test_labels, test_imgs)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRMm2v9t6bbj"
      },
      "source": [
        "#Further Study\n",
        "\n",
        "To learn more about post-training quantization and optimization, please check out the user guides at https://www.tensorflow.org/lite/performance/post_training_quantization"
      ]
    }
  ]
}